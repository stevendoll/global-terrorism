{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Global Terrorism Database\n",
    "https://www.start.umd.edu/gtd/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import numpy as np # imports a fast numerical programming library\n",
    "import scipy as sp #imports stats functions, amongst other things\n",
    "import matplotlib as mpl # this actually imports matplotlib\n",
    "import matplotlib.cm as cm #allows us easy access to colormaps\n",
    "import matplotlib.pyplot as plt #sets up plotting under plt\n",
    "import pandas as pd #lets us handle data as dataframes\n",
    "import seaborn as sns #sets up styles and gives us more plotting options\n",
    "\n",
    "import statsmodels\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "#sets up pandas table display\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "\n",
    "    file_ = \"data/globalterrorismdb_0615dist.csv\"\n",
    "    \n",
    "    #df = pd.read_csv(file_, header=0, nrows=100, dtype=str)\n",
    "    df = pd.read_csv(file_, header=0, dtype=str)\n",
    "\n",
    "    # fix dates\n",
    "    df['iyear'] = df['iyear'].astype(int)\n",
    "    df['imonth'] = df['imonth'].astype(int)\n",
    "    df['iday'] = df['iday'].astype(int)\n",
    "\n",
    "    df.ix[df.imonth == 0, 'imonth'] = 1\n",
    "    df.ix[df.iday == 0, 'iday'] = 1\n",
    "\n",
    "    df['date'] = df[['iyear', 'imonth', 'iday']].apply(lambda s : datetime(*s),axis = 1)\n",
    "        \n",
    "    print(\"Data loaded\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141966, 136)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# want to test if i'm reading all the data\n",
    "\n",
    "# text_cols = ['summary','alternative_txt','attacktype1_txt','attacktype2_txt','attacktype3_txt','targtype1_txt','targsubtype1_txt','natlty1_txt','targtype2_txt','targsubtype2_txt','natlty2_txt','targtype3_txt','targsubtype3_txt','natlty3_txt','motive','guncertain1','guncertain2','guncertain3','nperps','nperpcap','claimmode_txt','claimmode2_txt','claimmode3_txt','compclaim','weaptype1_txt','weapsubtype1_txt','weaptype2_txt','weapsubtype2_txt','weaptype3_txt','weapsubtype3_txt','weaptype4_txt','weapsubtype4_txt','weapdetail','propextent_txt','propcomment','ishostkid','nhostkid','nhostkidus','divert','kidhijcountry','ransom','ransomnote','hostkidoutcome_txt','addnotes','scite1','scite2','scite3','related']\n",
    "\n",
    "# df[text_cols] = df[text_cols].fillna('')\n",
    "\n",
    "# df['full_text'] = df[text_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# df.full_text = df.full_text.apply(lambda x: regex.sub(' ', x.lower()).replace('  ', ' ').replace('  ', ' '))\n",
    "\n",
    "# df.shape\n",
    "\n",
    "# words = []\n",
    "# word_count = 0\n",
    "\n",
    "# for i in range(140000,140999):\n",
    "    \n",
    "#     for col in text_cols:\n",
    "#         #df.loc[100][col]\n",
    "\n",
    "#         test_summ = df[i:i+1][col].apply(lambda x: regex.sub(' ', x.lower()).replace('  ', ' ').replace('  ', ' '))\n",
    "\n",
    "#         words = words + test_summ.tolist()[0].split()\n",
    "        \n",
    "\n",
    "# len(words)\n",
    "# # 78936 words 0, 999\n",
    "# # 97420 words 140000,140999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# text_cols = []\n",
    "# for col in df.columns:\n",
    "#     print(col, df[col].str.len().sum())\n",
    "#     text_cols.append(col)\n",
    "\n",
    "regex = re.compile('[^a-zA-Z\\s]')\n",
    "\n",
    "text_cols = ['summary','alternative_txt','attacktype1_txt','attacktype2_txt','attacktype3_txt','targtype1_txt','targsubtype1_txt','natlty1_txt','targtype2_txt','targsubtype2_txt','natlty2_txt','targtype3_txt','targsubtype3_txt','natlty3_txt','motive','guncertain1','guncertain2','guncertain3','nperps','nperpcap','claimmode_txt','claimmode2_txt','claimmode3_txt','compclaim','weaptype1_txt','weapsubtype1_txt','weaptype2_txt','weapsubtype2_txt','weaptype3_txt','weapsubtype3_txt','weaptype4_txt','weapsubtype4_txt','weapdetail','propextent_txt','propcomment','ishostkid','nhostkid','nhostkidus','divert','kidhijcountry','ransom','ransomnote','hostkidoutcome_txt','addnotes','scite1','scite2','scite3','related']\n",
    "\n",
    "df[text_cols] = df[text_cols].fillna('')\n",
    "\n",
    "df['full_text'] = df[text_cols].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "df.full_text = df.full_text.apply(lambda x: regex.sub(' ', x.lower()).replace('  ', ' ').replace('  ', ' '))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word_frequency(s, col_name='word_frequency'):\n",
    "    # takes a text string and returns a word frequency dataframe\n",
    "    \n",
    "    total_words = len(s)\n",
    "    \n",
    "    # Counter returns list of tuples\n",
    "    word_counter = Counter(s.split()) #.most_common()\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(word_counter, orient='index')\n",
    "    df.rename(columns={0: col_name}, inplace=True)\n",
    "    \n",
    "    df[col_name] = df[col_name] / total_words\n",
    "    \n",
    "    return df\n",
    "\n",
    "def word_tags(df):\n",
    "    # takes a word frequency dataframe and adds a column for tags\n",
    "    \n",
    "    tags = nltk.pos_tag(df.index)\n",
    "    df_tags = pd.DataFrame(tags, columns=['words', 'tag'])\n",
    "    df_tags.set_index('words', inplace=True) #.index.name = None\n",
    "    df_tags.index.name = None\n",
    "    \n",
    "    df = df.join(df_tags)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-2f60e9baa76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_early\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'early'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_later\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_frequency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_by_year\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m34\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'later'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#print(len(df_by_year[10:19].words))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/steven/anaconda/envs/py3k/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m             raise AttributeError(\"'%s' object has no attribute '%s'\" %\n\u001b[0;32m-> 2360\u001b[0;31m                                  (type(self).__name__, name))\n\u001b[0m\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "df_early = word_frequency(df_by_year[10:19].tolist()[0], 'early')\n",
    "df_later = word_frequency(df_by_year[25:34].tolist()[0], 'later')\n",
    "\n",
    "#print(len(df_by_year[10:19].words))\n",
    "\n",
    "df_words = word_tags(df_early.join(df_later))\n",
    "df_words['change'] = (df_words.later - df_words.early) / df_words.early\n",
    "#df_words = df_words.set_index('words')\n",
    "\n",
    "\n",
    "df_trends = df_words.sort_values('change', ascending=False)[0:20].append(df_words.sort_values('change')[0:10]).sort_values('change', ascending=False)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "df_trends.change.plot(kind='bar', ax=axes, figsize=(12, 10), title='Change in Job Listing Words')\n",
    "plt.savefig('word_frequency_change.png', bbox_inches='tight')\n",
    "\n",
    "df_words.sort_values('change', ascending=False)\n",
    "df_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>completely</th>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>something</th>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>different</th>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>now</th>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>And</th>\n",
       "      <td>0.02381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word_frequency\n",
       "completely         0.02381\n",
       "something          0.02381\n",
       "different          0.02381\n",
       "now                0.02381\n",
       "for                0.02381\n",
       "And                0.02381"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#nltk.pos_tag(df_words.index)\n",
    "text = 'And now for something completely different'\n",
    "\n",
    "df1 = word_frequency(text)\n",
    "\n",
    "tokens = text.split()\n",
    "#nltk.pos_tag()\n",
    "df1 #.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/steven/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
